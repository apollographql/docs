---
title: TN0005 - Overload Protection
tags: [server, router, sre]
---

Overload protection is a type of protection for your server to ensure it does not become unavaible when put under a large amount of load. Simplified, overload protection is where a service watches its resource usage and metrics, and when it notices the server may have difficulties serving a request (for example running out of memory (OOM)), it sheds incoming traffic until it's healthy again.

As the usage and size of your supergraph grow, the additional load created by creating new paths can be unexpectedly intense. Overload protection is one way to minimize the effects of an unintended or organic increase in pressure.

Instead of using load as a handwavy term for when something happens, let use some concrete examples of things that could cause this "load."

One of the easiest ones to describe is the [thundering herd problem](https://en.wikipedia.org/wiki/Thundering_herd_problem), which is when a number of processes/clients attempt to access limited computer resources. A multitude of different things can cause this, for example:

- Pod failures in Kubernetes that cause a smaller amount of pods to handle the same amount of traffic
- Push notifications/marketing events that drive traffic to the applications in a short period
- Features deployed that increase the load on the graph more than expected

A more graph-based problem is adding a entity relationship in the schema that causes a significant increase in traffic. For example in the [Star Wars schema](https://studio.apollographql.com/public/star-wars-swapi/home?variant=current), imagine if there was no link from `Person` to `Film`(though `PersonFilmsConnection`) and it was added today. Until the usage of that new connection in the schema flattens out, every deployment or event that causes traffic could cause a large amount of new load directly attributed to the change for the owner of the `Film` entity.

The last type of load-generating events to talk about are organic stress events. These are events that happen outside your company's control and cause excess stress on your system. An easy example of this can be found when examining online stores. Say someone with many Twitter followers tweets your store's page with an item they like. Their followers will flood this page, causing an organic increase in pressure in the system.

## Now, what do we do about this?

Most languages have some type of drop-in protection against this increase in pressure through a package; Node is no exception. For example, we'll look at one package named [overload-protection](https://www.npmjs.com/package/overload-protection) alongside `express`. This drag and drop package allows one to return a 503 based on the current event loop delay, the amount bytes used by the heap, and the amount of bytes used by Resident Set Size (RSS).

To use `overload-protection`, you'll include it in your express startup like this:

```js
const app = require("express")();
const protect = require("overload-protection")("express");
app.use(protect);
```

## Use With Apollo Server Express

If you're using `apollo-server-express`, you can add `overload-protection` via `express` middleware by adding the highlighted lines to your server creation:

```js {1,5}
const protect = require("overload-protection")("express");

async function startApolloServer(typeDefs, resolvers) {
  const app = express();
  app.use(protect);
  const httpServer = http.createServer(app);
  const server = new ApolloServer({
    typeDefs,
    resolvers,
    csrfPrevention: true,
    cache: "bounded",
    plugins: [ApolloServerPluginDrainHttpServer({ httpServer })],
  });

  await server.start();
  server.applyMiddleware({ app });
  await new Promise((resolve) => httpServer.listen({ port: 4000 }, resolve));
  console.log(`ðŸš€ Server ready at http://localhost:4000${server.graphqlPath}`);
}
```

This approach and additions also work if you are using the `@apollo/subgraph` to create your subgraphs in a similar way. Overload protection is not specific to GraphQL, so it's best to handle it outside of Apollo software. If you are running `apollo-server` instead, we have a guide on how to change to `apollo-server-express` from `apollo-server` to allow the use of additional `express` middleware. The guide can be found [here](https://www.apollographql.com/docs/apollo-server/integrations/middleware#swapping-out-apollo-server).

## Does this belong on the Router/Gateway or Subgraph?

The short answer is both, for different reasons. The router to allow to protect the overall availability of the graph. A subgraph should have overload protection to reduce the error rates of queries that include data from that specific subgraph.

### Router/Gateway

The main concern with the gateway is a build-up of pressure causing partial or cascading failures. If the gateway cannot properly shed the load placed on it, it will start to cause degraded performance. This happens due to a build-up of requests in the gateway. A single request to the gateway can turn into many requests to subgraphs. This expansion of requests can cause stress inside the gateway. When load creates this pressure, overload protection on the gateway can save your service from entirely falling over. This looks like a minor dip in availability vs. a total outage.

### Subgraph

A failure at the subgraph can cause a backup in the gateway. If this backup is due to load, overload protection becomes a way to short circuit the return of an error. This relieves the pressure in the gateway and the subgraph by allowing the gateway to return with errors faster.
