---
title: TN0005 - Overload Protection
tags: [server, router, sre]
---

Overload protection is adding some type of protection for your server to ensure it does not crash when put under a large amount of stress. The idea is we can have a service watch its resources and metrics, and when it notices, it's going to crash (think along the lines of Out of memory (OOM) killed). Overload protection is a huge sign of relief in a federated architecture. As the usage and size of your super graph grow, the pressure created by creating new paths can be unexpectedly intense. No one means to stress other services to the point of degraded service, but it happens. Overload protection is the way to minimize the effects of an unintended or organic increase in pressure.

As mentioned above, overload protection applies when your service is under stress. Instead of using stress as a handwavy term for when something happens, let us give some concrete examples of some things that could cause this "stress." The of the easiest ones to describe is the [thundering herd problem](https://www.notion.so/Overload-protection-ae3661da0d5940a0b300430f88873030#63e81848cc9b4c23bb96acad2a7c6a7b). A multitude of different things can cause this. Some examples are: pod failures in Kubernetes that cause a smaller amount of pods to handle the same amount of traffic, push notifications/marketing events that drive traffic to the applications in a short period, features deployed that increase the load on the graph more than expected, etc. Another more graph-based problem is adding a link in the schema that causes a significant increase in traffic. Think of the [Star Wars schema](https://studio.apollographql.com/public/star-wars-swapi/home?variant=current). If there was no link from `Person` to `Film`(though `PersonFilmsConnection`) and it is added. Until the usage of that new connection in the schema flattens out, every deployment or event that causes traffic could cause a large amount of stress. The last bucket to talk about is organic stress events. These are a large bucket of events that happen outside your company and cause excess stress on your system. An easy example of this can be found when examining online stores. Say someone with many Twitter followers tweets your store's page with an item they like. Their followers will flood this page, causing an organic increase in pressure in the system.

## Now, what do we do about this?!

Most languages have some type of drop-in protection against this increase in pressure through a package; Node is no exception. The package is named [overload-protection](https://www.npmjs.com/package/overload-protection). This drag and drop package allows one to return a 503 based on the current event loop delay, the amount bytes used by the heap, and the amount of bytes used by Rss.

It's straightforward to install with the base settings:

```TypeScript
const app = require('express')()
const protect = require('overload-protection')('express', protectCfg)
app.use(protect)
```

\*_I will be using express in these examples. This does work for other frameworks._

## But what about Apollo Server or a subgraph (federation)

If you're using `apollo-server-express`, it's straightforward. If your service looks something like the following:

```js
const app = express();
const httpServer = http.createServer(app);
const server = new ApolloServer({
  typeDefs,
  resolvers,
  csrfPrevention: true,
  cache: "bounded",
  plugins: [ApolloServerPluginDrainHttpServer({ httpServer })],
});

await server.start();
server.applyMiddleware({ app });
await new Promise((resolve) => httpServer.listen({ port: 4000 }, resolve));
console.log(`ðŸš€ Server ready at http://localhost:4000${server.graphqlPath}`);
```

overload protection can easily be added using the following:

```js
const protect = require("overload-protection")("express", protectCfg);

async function startApolloServer(typeDefs, resolvers) {
  const app = express();
  app.use(protect);
  const httpServer = http.createServer(app);
  const server = new ApolloServer({
    typeDefs,
    resolvers,
    csrfPrevention: true,
    cache: "bounded",
    plugins: [ApolloServerPluginDrainHttpServer({ httpServer })],
  });

  await server.start();
  server.applyMiddleware({ app });
  await new Promise((resolve) => httpServer.listen({ port: 4000 }, resolve));
  console.log(`ðŸš€ Server ready at http://localhost:4000${server.graphqlPath}`);
}
```

The difference between the two snippets is lines 1 and 5 are added in the second snippet. This approach and additions also work if you are using the @apollo/subgraph to create your subgraphs in a similar way. Unfortunately, the base Apollo server cannot implement overload protection. Luckily the team at apollo already has a guide on how to change from apollo-server to apollo-server-express! The guide can be found [here](https://www.apollographql.com/docs/apollo-server/integrations/middleware#swapping-out-apollo-server).
